{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "cell_id": "672fa07e-10ee-4b6c-8779-1076a95b9a43",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 90
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Install",
   "metadata": {
    "colab_type": "text",
    "id": "7wNjDKdQy35h",
    "cell_id": "00001-6bee83b5-0004-406d-9630-a8667ba479f0",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 82
   }
  },
  {
   "cell_type": "code",
   "source": "import os\nos.chdir('/work/AI-2022-genart')",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt3igws3eiVp",
    "cell_id": "00003-c6159dcc-e41f-4d41-a4e8-2323b663ea3a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d0674a74",
    "execution_start": 1667911977593,
    "execution_millis": 135285,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 94
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1EySlOXwwoa",
    "cell_id": "00004-011bd225-22a9-4ca4-8fdd-44533c6c80b5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7958d4a9",
    "execution_start": 1667911977593,
    "execution_millis": 2235,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 696
   },
   "source": "!pip install -r requirements.txt",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: torch>=1.4.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.12.1)\nRequirement already satisfied: torchvision>=0.5.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.13.1)\nRequirement already satisfied: dominate>=2.4.0 in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.7.0)\nRequirement already satisfied: visdom>=0.1.8.8 in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.2.3)\nRequirement already satisfied: wandb in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.13.5)\nRequirement already satisfied: typing-extensions in /shared-libs/python3.9/py/lib/python3.9/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.4.0)\nRequirement already satisfied: requests in /shared-libs/python3.9/py/lib/python3.9/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.28.1)\nRequirement already satisfied: numpy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.23.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (9.2.0)\nRequirement already satisfied: networkx in /root/venv/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.8.8)\nRequirement already satisfied: scipy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.9.3)\nRequirement already satisfied: jsonpatch in /root/venv/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.32)\nRequirement already satisfied: six in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\nRequirement already satisfied: tornado in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.2)\nRequirement already satisfied: websocket-client in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.4.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /root/venv/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\nRequirement already satisfied: setproctitle in /root/venv/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (1.3.2)\nRequirement already satisfied: shortuuid>=0.5.0 in /root/venv/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (1.0.9)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (58.1.0)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /root/venv/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (1.10.1)\nRequirement already satisfied: PyYAML in /root/venv/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (6.0)\nRequirement already satisfied: GitPython>=1.0.0 in /root/venv/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (3.1.29)\nRequirement already satisfied: psutil>=5.0.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (5.9.3)\nRequirement already satisfied: pathtools in /root/venv/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (0.1.2)\nRequirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (3.19.6)\nRequirement already satisfied: promise<3,>=2.0 in /root/venv/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (2.3)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (8.1.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /root/venv/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.4)\nRequirement already satisfied: jsonpointer>=1.9 in /root/venv/lib/python3.9/site-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /root/venv/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.0)\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Datasets\n\nDownload one of the official datasets with:\n\n-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n\nOr use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets).",
   "metadata": {
    "colab_type": "text",
    "id": "8daqlgVhw29P",
    "cell_id": "00005-5c5dbb11-25a8-493e-9b04-443b11057c60",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 193.1875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrdOettJxaCc",
    "cell_id": "00006-331ada52-9ba2-42d4-a8ff-a5a88f16ede7",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c6d5db16",
    "execution_start": 1667911979830,
    "execution_millis": 32446,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 696
   },
   "source": "!bash ./datasets/download_pix2pix_dataset.sh facades",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "Specified [facades]\nWARNING: timestamping does nothing in combination with -O. See the manual\nfor details.\n\n--2022-11-08 12:52:59--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\nResolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\nConnecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 30168306 (29M) [application/x-gzip]\nSaving to: ‘./datasets/facades.tar.gz’\n\n./datasets/facades. 100%[===================>]  28.77M  1.72MB/s    in 30s     \n\n2022-11-08 12:53:30 (983 KB/s) - ‘./datasets/facades.tar.gz’ saved [30168306/30168306]\n\nfacades/\nfacades/test/\nfacades/test/27.jpg\nfacades/test/5.jpg\nfacades/test/72.jpg\nfacades/test/1.jpg\nfacades/test/10.jpg\nfacades/test/100.jpg\nfacades/test/101.jpg\nfacades/test/102.jpg\nfacades/test/103.jpg\nfacades/test/104.jpg\nfacades/test/105.jpg\nfacades/test/106.jpg\nfacades/test/11.jpg\nfacades/test/12.jpg\nfacades/test/13.jpg\nfacades/test/14.jpg\nfacades/test/15.jpg\nfacades/test/16.jpg\nfacades/test/17.jpg\nfacades/test/18.jpg\nfacades/test/19.jpg\nfacades/test/2.jpg\nfacades/test/20.jpg\nfacades/test/21.jpg\nfacades/test/22.jpg\nfacades/test/23.jpg\nfacades/test/24.jpg\nfacades/test/25.jpg\nfacades/test/26.jpg\nfacades/test/50.jpg\nfacades/test/51.jpg\nfacades/test/52.jpg\nfacades/test/53.jpg\nfacades/test/54.jpg\nfacades/test/55.jpg\nfacades/test/56.jpg\nfacades/test/57.jpg\nfacades/test/58.jpg\nfacades/test/59.jpg\nfacades/test/6.jpg\nfacades/test/60.jpg\nfacades/test/61.jpg\nfacades/test/62.jpg\nfacades/test/63.jpg\nfacades/test/64.jpg\nfacades/test/65.jpg\nfacades/test/66.jpg\nfacades/test/67.jpg\nfacades/test/68.jpg\nfacades/test/69.jpg\nfacades/test/7.jpg\nfacades/test/70.jpg\nfacades/test/71.jpg\nfacades/test/73.jpg\nfacades/test/74.jpg\nfacades/test/75.jpg\nfacades/test/76.jpg\nfacades/test/77.jpg\nfacades/test/78.jpg\nfacades/test/79.jpg\nfacades/test/8.jpg\nfacades/test/80.jpg\nfacades/test/81.jpg\nfacades/test/82.jpg\nfacades/test/83.jpg\nfacades/test/84.jpg\nfacades/test/85.jpg\nfacades/test/86.jpg\nfacades/test/87.jpg\nfacades/test/88.jpg\nfacades/test/89.jpg\nfacades/test/9.jpg\nfacades/test/90.jpg\nfacades/test/91.jpg\nfacades/test/92.jpg\nfacades/test/93.jpg\nfacades/test/94.jpg\nfacades/test/95.jpg\nfacades/test/96.jpg\nfacades/test/97.jpg\nfacades/test/98.jpg\nfacades/test/99.jpg\nfacades/test/28.jpg\nfacades/test/29.jpg\nfacades/test/3.jpg\nfacades/test/30.jpg\nfacades/test/31.jpg\nfacades/test/32.jpg\nfacades/test/33.jpg\nfacades/test/34.jpg\nfacades/test/35.jpg\nfacades/test/36.jpg\nfacades/test/37.jpg\nfacades/test/38.jpg\nfacades/test/39.jpg\nfacades/test/4.jpg\nfacades/test/40.jpg\nfacades/test/41.jpg\nfacades/test/42.jpg\nfacades/test/43.jpg\nfacades/test/44.jpg\nfacades/test/45.jpg\nfacades/test/46.jpg\nfacades/test/47.jpg\nfacades/test/48.jpg\nfacades/test/49.jpg\nfacades/train/\nfacades/train/1.jpg\nfacades/train/10.jpg\nfacades/train/100.jpg\nfacades/train/101.jpg\nfacades/train/102.jpg\nfacades/train/103.jpg\nfacades/train/104.jpg\nfacades/train/105.jpg\nfacades/train/106.jpg\nfacades/train/107.jpg\nfacades/train/108.jpg\nfacades/train/109.jpg\nfacades/train/11.jpg\nfacades/train/110.jpg\nfacades/train/111.jpg\nfacades/train/112.jpg\nfacades/train/113.jpg\nfacades/train/114.jpg\nfacades/train/115.jpg\nfacades/train/116.jpg\nfacades/train/117.jpg\nfacades/train/118.jpg\nfacades/train/119.jpg\nfacades/train/12.jpg\nfacades/train/120.jpg\nfacades/train/121.jpg\nfacades/train/122.jpg\nfacades/train/123.jpg\nfacades/train/124.jpg\nfacades/train/125.jpg\nfacades/train/126.jpg\nfacades/train/309.jpg\nfacades/train/31.jpg\nfacades/train/310.jpg\nfacades/train/311.jpg\nfacades/train/312.jpg\nfacades/train/313.jpg\nfacades/train/314.jpg\nfacades/train/315.jpg\nfacades/train/316.jpg\nfacades/train/317.jpg\nfacades/train/318.jpg\nfacades/train/319.jpg\nfacades/train/32.jpg\nfacades/train/320.jpg\nfacades/train/321.jpg\nfacades/train/322.jpg\nfacades/train/323.jpg\nfacades/train/324.jpg\nfacades/train/325.jpg\nfacades/train/326.jpg\nfacades/train/327.jpg\nfacades/train/328.jpg\nfacades/train/329.jpg\nfacades/train/390.jpg\nfacades/train/391.jpg\nfacades/train/392.jpg\nfacades/train/393.jpg\nfacades/train/394.jpg\nfacades/train/395.jpg\nfacades/train/396.jpg\nfacades/train/397.jpg\nfacades/train/398.jpg\nfacades/train/399.jpg\nfacades/train/4.jpg\nfacades/train/40.jpg\nfacades/train/400.jpg\nfacades/train/41.jpg\nfacades/train/42.jpg\nfacades/train/43.jpg\nfacades/train/44.jpg\nfacades/train/45.jpg\nfacades/train/46.jpg\nfacades/train/47.jpg\nfacades/train/48.jpg\nfacades/train/49.jpg\nfacades/train/5.jpg\nfacades/train/50.jpg\nfacades/train/51.jpg\nfacades/train/52.jpg\nfacades/train/53.jpg\nfacades/train/54.jpg\nfacades/train/55.jpg\nfacades/train/56.jpg\nfacades/train/57.jpg\nfacades/train/58.jpg\nfacades/train/59.jpg\nfacades/train/6.jpg\nfacades/train/60.jpg\nfacades/train/61.jpg\nfacades/train/222.jpg\nfacades/train/223.jpg\nfacades/train/224.jpg\nfacades/train/225.jpg\nfacades/train/226.jpg\nfacades/train/227.jpg\nfacades/train/228.jpg\nfacades/train/229.jpg\nfacades/train/23.jpg\nfacades/train/230.jpg\nfacades/train/231.jpg\nfacades/train/232.jpg\nfacades/train/233.jpg\nfacades/train/234.jpg\nfacades/train/235.jpg\nfacades/train/236.jpg\nfacades/train/237.jpg\nfacades/train/238.jpg\nfacades/train/239.jpg\nfacades/train/24.jpg\nfacades/train/240.jpg\nfacades/train/241.jpg\nfacades/train/242.jpg\nfacades/train/243.jpg\nfacades/train/244.jpg\nfacades/train/245.jpg\nfacades/train/156.jpg\nfacades/train/157.jpg\nfacades/train/158.jpg\nfacades/train/159.jpg\nfacades/train/16.jpg\nfacades/train/160.jpg\nfacades/train/161.jpg\nfacades/train/162.jpg\nfacades/train/163.jpg\nfacades/train/164.jpg\nfacades/train/165.jpg\nfacades/train/166.jpg\nfacades/train/167.jpg\nfacades/train/168.jpg\nfacades/train/169.jpg\nfacades/train/17.jpg\nfacades/train/170.jpg\nfacades/train/171.jpg\nfacades/train/172.jpg\nfacades/train/173.jpg\nfacades/train/174.jpg\nfacades/train/175.jpg\nfacades/train/176.jpg\nfacades/train/177.jpg\nfacades/train/178.jpg\nfacades/train/179.jpg\nfacades/train/18.jpg\nfacades/train/180.jpg\nfacades/train/181.jpg\nfacades/train/182.jpg\nfacades/train/183.jpg\nfacades/train/184.jpg\nfacades/train/185.jpg\nfacades/train/186.jpg\nfacades/train/187.jpg\nfacades/train/188.jpg\nfacades/train/189.jpg\nfacades/train/19.jpg\nfacades/train/127.jpg\nfacades/train/155.jpg\nfacades/train/190.jpg\nfacades/train/221.jpg\nfacades/train/246.jpg\nfacades/train/27.jpg\nfacades/train/29.jpg\nfacades/train/308.jpg\nfacades/train/33.jpg\nfacades/train/350.jpg\nfacades/train/370.jpg\nfacades/train/39.jpg\nfacades/train/62.jpg\nfacades/train/270.jpg\nfacades/train/271.jpg\nfacades/train/272.jpg\nfacades/train/273.jpg\nfacades/train/274.jpg\nfacades/train/275.jpg\nfacades/train/276.jpg\nfacades/train/277.jpg\nfacades/train/278.jpg\nfacades/train/279.jpg\nfacades/train/28.jpg\nfacades/train/280.jpg\nfacades/train/281.jpg\nfacades/train/282.jpg\nfacades/train/283.jpg\nfacades/train/284.jpg\nfacades/train/285.jpg\nfacades/train/286.jpg\nfacades/train/287.jpg\nfacades/train/288.jpg\nfacades/train/289.jpg\nfacades/train/351.jpg\nfacades/train/352.jpg\nfacades/train/353.jpg\nfacades/train/354.jpg\nfacades/train/355.jpg\nfacades/train/356.jpg\nfacades/train/357.jpg\nfacades/train/358.jpg\nfacades/train/359.jpg\nfacades/train/36.jpg\nfacades/train/360.jpg\nfacades/train/361.jpg\nfacades/train/362.jpg\nfacades/train/363.jpg\nfacades/train/364.jpg\nfacades/train/365.jpg\nfacades/train/366.jpg\nfacades/train/367.jpg\nfacades/train/368.jpg\nfacades/train/369.jpg\nfacades/train/37.jpg\nfacades/train/63.jpg\nfacades/train/64.jpg\nfacades/train/65.jpg\nfacades/train/66.jpg\nfacades/train/67.jpg\nfacades/train/68.jpg\nfacades/train/69.jpg\nfacades/train/7.jpg\nfacades/train/70.jpg\nfacades/train/71.jpg\nfacades/train/72.jpg\nfacades/train/73.jpg\nfacades/train/74.jpg\nfacades/train/75.jpg\nfacades/train/76.jpg\nfacades/train/77.jpg\nfacades/train/78.jpg\nfacades/train/79.jpg\nfacades/train/8.jpg\nfacades/train/80.jpg\nfacades/train/81.jpg\nfacades/train/82.jpg\nfacades/train/83.jpg\nfacades/train/84.jpg\nfacades/train/85.jpg\nfacades/train/86.jpg\nfacades/train/87.jpg\nfacades/train/88.jpg\nfacades/train/89.jpg\nfacades/train/9.jpg\nfacades/train/90.jpg\nfacades/train/91.jpg\nfacades/train/92.jpg\nfacades/train/93.jpg\nfacades/train/94.jpg\nfacades/train/95.jpg\nfacades/train/96.jpg\nfacades/train/97.jpg\nfacades/train/98.jpg\nfacades/train/99.jpg\nfacades/train/128.jpg\nfacades/train/129.jpg\nfacades/train/13.jpg\nfacades/train/130.jpg\nfacades/train/131.jpg\nfacades/train/132.jpg\nfacades/train/133.jpg\nfacades/train/134.jpg\nfacades/train/135.jpg\nfacades/train/136.jpg\nfacades/train/137.jpg\nfacades/train/138.jpg\nfacades/train/139.jpg\nfacades/train/14.jpg\nfacades/train/140.jpg\nfacades/train/141.jpg\nfacades/train/142.jpg\nfacades/train/143.jpg\nfacades/train/144.jpg\nfacades/train/145.jpg\nfacades/train/146.jpg\nfacades/train/147.jpg\nfacades/train/148.jpg\nfacades/train/149.jpg\nfacades/train/15.jpg\nfacades/train/150.jpg\nfacades/train/151.jpg\nfacades/train/152.jpg\nfacades/train/153.jpg\nfacades/train/154.jpg\nfacades/train/191.jpg\nfacades/train/192.jpg\nfacades/train/193.jpg\nfacades/train/194.jpg\nfacades/train/195.jpg\nfacades/train/196.jpg\nfacades/train/197.jpg\nfacades/train/198.jpg\nfacades/train/199.jpg\nfacades/train/2.jpg\nfacades/train/20.jpg\nfacades/train/200.jpg\nfacades/train/201.jpg\nfacades/train/202.jpg\nfacades/train/203.jpg\nfacades/train/204.jpg\nfacades/train/205.jpg\nfacades/train/206.jpg\nfacades/train/207.jpg\nfacades/train/208.jpg\nfacades/train/209.jpg\nfacades/train/21.jpg\nfacades/train/210.jpg\nfacades/train/211.jpg\nfacades/train/212.jpg\nfacades/train/213.jpg\nfacades/train/214.jpg\nfacades/train/215.jpg\nfacades/train/216.jpg\nfacades/train/217.jpg\nfacades/train/218.jpg\nfacades/train/219.jpg\nfacades/train/22.jpg\nfacades/train/220.jpg\nfacades/train/247.jpg\nfacades/train/248.jpg\nfacades/train/249.jpg\nfacades/train/25.jpg\nfacades/train/250.jpg\nfacades/train/251.jpg\nfacades/train/252.jpg\nfacades/train/253.jpg\nfacades/train/254.jpg\nfacades/train/255.jpg\nfacades/train/256.jpg\nfacades/train/257.jpg\nfacades/train/258.jpg\nfacades/train/259.jpg\nfacades/train/26.jpg\nfacades/train/260.jpg\nfacades/train/261.jpg\nfacades/train/262.jpg\nfacades/train/263.jpg\nfacades/train/264.jpg\nfacades/train/265.jpg\nfacades/train/266.jpg\nfacades/train/267.jpg\nfacades/train/268.jpg\nfacades/train/269.jpg\nfacades/train/330.jpg\nfacades/train/331.jpg\nfacades/train/332.jpg\nfacades/train/333.jpg\nfacades/train/334.jpg\nfacades/train/335.jpg\nfacades/train/336.jpg\nfacades/train/337.jpg\nfacades/train/338.jpg\nfacades/train/339.jpg\nfacades/train/34.jpg\nfacades/train/340.jpg\nfacades/train/341.jpg\nfacades/train/342.jpg\nfacades/train/343.jpg\nfacades/train/344.jpg\nfacades/train/345.jpg\nfacades/train/346.jpg\nfacades/train/347.jpg\nfacades/train/348.jpg\nfacades/train/349.jpg\nfacades/train/35.jpg\nfacades/train/290.jpg\nfacades/train/291.jpg\nfacades/train/292.jpg\nfacades/train/293.jpg\nfacades/train/294.jpg\nfacades/train/295.jpg\nfacades/train/296.jpg\nfacades/train/297.jpg\nfacades/train/298.jpg\nfacades/train/299.jpg\nfacades/train/3.jpg\nfacades/train/30.jpg\nfacades/train/300.jpg\nfacades/train/301.jpg\nfacades/train/302.jpg\nfacades/train/303.jpg\nfacades/train/304.jpg\nfacades/train/305.jpg\nfacades/train/306.jpg\nfacades/train/307.jpg\nfacades/train/371.jpg\nfacades/train/372.jpg\nfacades/train/373.jpg\nfacades/train/374.jpg\nfacades/train/375.jpg\nfacades/train/376.jpg\nfacades/train/377.jpg\nfacades/train/378.jpg\nfacades/train/379.jpg\nfacades/train/38.jpg\nfacades/train/380.jpg\nfacades/train/381.jpg\nfacades/train/382.jpg\nfacades/train/383.jpg\nfacades/train/384.jpg\nfacades/train/385.jpg\nfacades/train/386.jpg\nfacades/train/387.jpg\nfacades/train/388.jpg\nfacades/train/389.jpg\nfacades/val/\nfacades/val/30.jpg\nfacades/val/50.jpg\nfacades/val/73.jpg\nfacades/val/1.jpg\nfacades/val/10.jpg\nfacades/val/100.jpg\nfacades/val/11.jpg\nfacades/val/12.jpg\nfacades/val/13.jpg\nfacades/val/14.jpg\nfacades/val/15.jpg\nfacades/val/16.jpg\nfacades/val/17.jpg\nfacades/val/18.jpg\nfacades/val/19.jpg\nfacades/val/2.jpg\nfacades/val/20.jpg\nfacades/val/21.jpg\nfacades/val/22.jpg\nfacades/val/23.jpg\nfacades/val/24.jpg\nfacades/val/25.jpg\nfacades/val/26.jpg\nfacades/val/27.jpg\nfacades/val/28.jpg\nfacades/val/29.jpg\nfacades/val/3.jpg\nfacades/val/51.jpg\nfacades/val/52.jpg\nfacades/val/53.jpg\nfacades/val/54.jpg\nfacades/val/55.jpg\nfacades/val/56.jpg\nfacades/val/57.jpg\nfacades/val/58.jpg\nfacades/val/59.jpg\nfacades/val/6.jpg\nfacades/val/60.jpg\nfacades/val/61.jpg\nfacades/val/62.jpg\nfacades/val/63.jpg\nfacades/val/64.jpg\nfacades/val/65.jpg\nfacades/val/66.jpg\nfacades/val/67.jpg\nfacades/val/68.jpg\nfacades/val/69.jpg\nfacades/val/7.jpg\nfacades/val/70.jpg\nfacades/val/71.jpg\nfacades/val/72.jpg\nfacades/val/74.jpg\nfacades/val/75.jpg\nfacades/val/76.jpg\nfacades/val/77.jpg\nfacades/val/78.jpg\nfacades/val/79.jpg\nfacades/val/8.jpg\nfacades/val/80.jpg\nfacades/val/81.jpg\nfacades/val/82.jpg\nfacades/val/83.jpg\nfacades/val/84.jpg\nfacades/val/85.jpg\nfacades/val/86.jpg\nfacades/val/87.jpg\nfacades/val/88.jpg\nfacades/val/89.jpg\nfacades/val/9.jpg\nfacades/val/90.jpg\nfacades/val/91.jpg\nfacades/val/92.jpg\nfacades/val/93.jpg\nfacades/val/94.jpg\nfacades/val/95.jpg\nfacades/val/96.jpg\nfacades/val/97.jpg\nfacades/val/98.jpg\nfacades/val/99.jpg\nfacades/val/31.jpg\nfacades/val/32.jpg\nfacades/val/33.jpg\nfacades/val/34.jpg\nfacades/val/35.jpg\nfacades/val/36.jpg\nfacades/val/37.jpg\nfacades/val/38.jpg\nfacades/val/39.jpg\nfacades/val/4.jpg\nfacades/val/40.jpg\nfacades/val/41.jpg\nfacades/val/42.jpg\nfacades/val/43.jpg\nfacades/val/44.jpg\nfacades/val/45.jpg\nfacades/val/46.jpg\nfacades/val/47.jpg\nfacades/val/48.jpg\nfacades/val/49.jpg\nfacades/val/5.jpg\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Pretrained models\n\nDownload one of the official pretrained models with:\n\n-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n\nOr add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`",
   "metadata": {
    "colab_type": "text",
    "id": "gdUz4116xhpm",
    "cell_id": "00007-e16eff27-fc6d-4fae-a59b-150390694ea4",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 193.1875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GC2DEP4M0OsS",
    "cell_id": "00008-f7c1b9bb-fc2f-478e-a1ab-06012b18579e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "39352e4a",
    "execution_start": 1667912012323,
    "execution_millis": 10741,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 402.125
   },
   "source": "!bash ./scripts/download_pix2pix_model.sh facades_label2photo",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "Note: available models are edges2shoes, sat2map, map2sat, facades_label2photo, and day2night\nSpecified [facades_label2photo]\nWARNING: timestamping does nothing in combination with -O. See the manual\nfor details.\n\n--2022-11-08 12:53:32--  http://efrosgans.eecs.berkeley.edu/pix2pix/models-pytorch/facades_label2photo.pth\nResolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\nConnecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 217704720 (208M)\nSaving to: ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’\n\n./checkpoints/facad 100%[===================>] 207.62M  45.5MB/s    in 8.9s    \n\n2022-11-08 12:53:41 (23.2 MB/s) - ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’ saved [217704720/217704720]\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Training\n\n-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n\nChange the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A.",
   "metadata": {
    "colab_type": "text",
    "id": "yFw1kDQBx3LN",
    "cell_id": "00009-227e6d08-e5ea-4801-9e67-aa2d3089cbe8",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 179.1875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB",
    "cell_id": "00010-b4a2169c-a39d-4b14-a48e-c29c87711dd4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "25ec6493",
    "execution_start": 1667912023069,
    "execution_millis": 2936,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 696
   },
   "source": "!python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA --display_id -1",
   "outputs": [
    {
     "name": "stdout",
     "text": "----------------- Options ---------------\n               batch_size: 1                             \n                    beta1: 0.5                           \n          checkpoints_dir: ./checkpoints                 \n           continue_train: False                         \n                crop_size: 256                           \n                 dataroot: ./datasets/facades            \t[default: None]\n             dataset_mode: aligned                       \n                direction: BtoA                          \t[default: AtoB]\n              display_env: main                          \n             display_freq: 400                           \n               display_id: -1                            \t[default: 1]\n            display_ncols: 4                             \n             display_port: 8097                          \n           display_server: http://localhost              \n          display_winsize: 256                           \n                    epoch: latest                        \n              epoch_count: 1                             \n                 gan_mode: vanilla                       \n                  gpu_ids: -1                            \n                init_gain: 0.02                          \n                init_type: normal                        \n                 input_nc: 3                             \n                  isTrain: True                          \t[default: None]\n                lambda_L1: 100.0                         \n                load_iter: 0                             \t[default: 0]\n                load_size: 286                           \n                       lr: 0.0002                        \n           lr_decay_iters: 50                            \n                lr_policy: linear                        \n         max_dataset_size: inf                           \n                    model: pix2pix                       \t[default: cycle_gan]\n                 n_epochs: 100                           \n           n_epochs_decay: 100                           \n               n_layers_D: 3                             \n                     name: facades_pix2pix               \t[default: experiment_name]\n                      ndf: 64                            \n                     netD: basic                         \n                     netG: unet_256                      \n                      ngf: 64                            \n               no_dropout: False                         \n                  no_flip: False                         \n                  no_html: False                         \n                     norm: batch                         \n              num_threads: 4                             \n                output_nc: 3                             \n                    phase: train                         \n                pool_size: 0                             \n               preprocess: resize_and_crop               \n               print_freq: 100                           \n             save_by_iter: False                         \n          save_epoch_freq: 5                             \n         save_latest_freq: 5000                          \n           serial_batches: False                         \n                   suffix:                               \n         update_html_freq: 1000                          \n                use_wandb: False                         \n                  verbose: False                         \n       wandb_project_name: CycleGAN-and-pix2pix          \n----------------- End -------------------\ndataset [AlignedDataset] was created\nThe number of training images = 400\ninitialize network with normal\ninitialize network with normal\nmodel [Pix2PixModel] was created\n---------- Networks initialized -------------\n[Network G] Total number of parameters : 54.414 M\n[Network D] Total number of parameters : 2.769 M\n-----------------------------------------------\ncreate web directory ./checkpoints/facades_pix2pix/web...\n  0%|                                                   | 0/200 [00:00<?, ?it/s]/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\nlearning rate 0.0002000 -> 0.0002000\n\n0it [00:00, ?it/s]\u001b[A",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Testing\n\n-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n\nChange the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n\n> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n\n> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n\n> See a list of currently available models at ./scripts/download_pix2pix_model.sh",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl",
    "cell_id": "00011-fc9fbcea-9d46-481b-8d04-89e0aabca939",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 324.78125
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mey7o6j-0368",
    "cell_id": "00012-86ba9cd0-b599-4083-b89c-a93a423d20ef",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "5bbed90f",
    "execution_start": 1667911886793,
    "execution_millis": 217,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 106.6875
   },
   "source": "!ls checkpoints/",
   "outputs": [
    {
     "name": "stdout",
     "text": "facades_label2photo_pretrained\tfacades_pix2pix\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCsKkEq0yGh0",
    "cell_id": "00013-8dd70dda-ae31-43d9-8012-b58f341b84d4",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "18722ac5",
    "execution_start": 1667911887018,
    "execution_millis": 2577,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 701
   },
   "source": "!python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_label2photo_pretrained --use_wandb",
   "outputs": [
    {
     "name": "stdout",
     "text": "----------------- Options ---------------\n             aspect_ratio: 1.0                           \n               batch_size: 1                             \n          checkpoints_dir: ./checkpoints                 \n                crop_size: 256                           \n                 dataroot: ./datasets/facades            \t[default: None]\n             dataset_mode: aligned                       \n                direction: BtoA                          \t[default: AtoB]\n          display_winsize: 256                           \n                    epoch: latest                        \n                     eval: False                         \n                  gpu_ids: 0                             \n                init_gain: 0.02                          \n                init_type: normal                        \n                 input_nc: 3                             \n                  isTrain: False                         \t[default: None]\n                load_iter: 0                             \t[default: 0]\n                load_size: 256                           \n         max_dataset_size: inf                           \n                    model: pix2pix                       \t[default: test]\n               n_layers_D: 3                             \n                     name: facades_label2photo_pretrained\t[default: experiment_name]\n                      ndf: 64                            \n                     netD: basic                         \n                     netG: unet_256                      \n                      ngf: 64                            \n               no_dropout: False                         \n                  no_flip: False                         \n                     norm: batch                         \n                 num_test: 50                            \n              num_threads: 4                             \n                output_nc: 3                             \n                    phase: test                          \n               preprocess: resize_and_crop               \n              results_dir: ./results/                    \n           serial_batches: False                         \n                   suffix:                               \n                use_wandb: True                          \t[default: False]\n                  verbose: False                         \n       wandb_project_name: CycleGAN-and-pix2pix          \n----------------- End -------------------\nTraceback (most recent call last):\n  File \"/work/AI-2022-genart/pytorch-CycleGAN-and-pix2pix/test.py\", line 43, in <module>\n    opt = TestOptions().parse()  # get test options\n  File \"/work/AI-2022-genart/pytorch-CycleGAN-and-pix2pix/options/base_options.py\", line 136, in parse\n    torch.cuda.set_device(opt.gpu_ids[0])\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 314, in set_device\n    torch._C._cuda_setDevice(device)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 217, in _lazy_init\n    torch._C._cuda_init()\nRuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Visualize",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKIPUByfiN",
    "cell_id": "00014-07a48d68-ebea-47d5-860d-d2f16bead4c4",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 82
   }
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\nimg = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\nplt.imshow(img)",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq",
    "cell_id": "00015-5ef3febc-870d-4fc3-9d42-edc2c8fe167c",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "4295bd6a",
    "execution_start": 1667911926451,
    "execution_millis": 29,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 193.1875
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/work/results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/work/results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img)\n",
      "File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/matplotlib/pyplot.py:2111\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimread)\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(fname, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 2111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/matplotlib/image.py:1541\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1540\u001b[0m         )\n\u001b[0;32m-> 1541\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1543\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1544\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/PIL/ImageFile.py:104\u001b[0m, in \u001b[0;36mImageFile.__init__\u001b[0;34m(self, fp, filename)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodermaxblock \u001b[38;5;241m=\u001b[39m MAXBLOCK\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# filename\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/work/results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png'"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ",
    "cell_id": "00016-a9109168-d0e8-48b7-a06a-81db8d76a22b",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "d2641a24",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 94
   },
   "source": "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\nplt.imshow(img)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErK5OC1j1LH4",
    "cell_id": "00017-48b37828-f11c-4067-b885-c8797169609a",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "cd2d154e",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 94
   },
   "source": "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\nplt.imshow(img)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=689e701f-f532-4259-9a71-057a4c9dc0af' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pix2pix",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "deepnote_notebook_id": "0655082d-4cbd-4009-ae47-f70dc44930b6",
  "deepnote": {},
  "deepnote_execution_queue": [
   {
    "cellId": "00010-b4a2169c-a39d-4b14-a48e-c29c87711dd4",
    "sessionId": "255fae61-2632-4f33-9fe5-28a39accf471",
    "msgId": "a60de712-2358-4ec8-8944-aa7836173c20"
   },
   {
    "cellId": "00012-86ba9cd0-b599-4083-b89c-a93a423d20ef",
    "sessionId": "255fae61-2632-4f33-9fe5-28a39accf471",
    "msgId": "3c4c7907-f39b-4612-8004-4404d12cc0c3"
   },
   {
    "cellId": "00013-8dd70dda-ae31-43d9-8012-b58f341b84d4",
    "sessionId": "255fae61-2632-4f33-9fe5-28a39accf471",
    "msgId": "2b1f7b63-85a5-4b9c-a8d3-2eadb114971c"
   },
   {
    "cellId": "00015-5ef3febc-870d-4fc3-9d42-edc2c8fe167c",
    "sessionId": "255fae61-2632-4f33-9fe5-28a39accf471",
    "msgId": "f61d825a-371c-4211-be3c-2b4400213968"
   },
   {
    "cellId": "00016-a9109168-d0e8-48b7-a06a-81db8d76a22b",
    "sessionId": "255fae61-2632-4f33-9fe5-28a39accf471",
    "msgId": "7cf08b5e-3b97-44c7-859d-a5d0abf271fe"
   },
   {
    "cellId": "00017-48b37828-f11c-4067-b885-c8797169609a",
    "sessionId": "255fae61-2632-4f33-9fe5-28a39accf471",
    "msgId": "d86af341-5190-4a52-8e48-027aa912adc5"
   }
  ]
 }
}